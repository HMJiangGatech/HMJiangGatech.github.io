<!DOCTYPE html><html><head>
      <title>2019SummerIntern</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///C:\Users\Administrator\.atom\packages\markdown-preview-enhanced\node_modules\@shd101wyy\mume\dependencies\katex\katex.min.css">
      
      
      
      
      
      
      
      
      

      <style> 
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
 
      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview   ">
      <h1 class="mume-header" id="2019-internship-project">2019 Internship Project</h1>

<ul>
<li><a href="#2019-internship-project">2019 Internship Project</a>
<ul>
<li><a href="#toolkit">Toolkit</a>
<ul>
<li><a href="#server">Server</a></li>
<li><a href="#docker">Docker</a>
<ul>
<li><a href="#run-a-docker-image">Run a docker image</a></li>
<li><a href="#attach-to-a-running-docker-container">Attach to a running docker container</a></li>
<li><a href="#file-permission-issue">File Permission Issue</a></li>
<li><a href="#build-a-docker-image">Build a docker image</a></li>
<li><a href="#cheatsheet">Cheatsheet</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#project-1-semi-supervised-learning-of-mnli-by-generating-labeled-paired-sample-using-conditional-cyclegan">Project 1: Semi-supervised Learning of MNLI by Generating Labeled Paired Sample using Conditional CycleGAN</a>
<ul>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#difficulty">Difficulty</a></li>
<li><a href="#ideas">Ideas</a></li>
<li><a href="#reading-list">Reading List</a></li>
<li><a href="#baselines">Baselines</a></li>
<li><a href="#data">Data</a></li>
</ul>
</li>
<li><a href="#project-2-emsemble-model">Project 2: Emsemble Model</a>
<ul>
<li><a href="#boosting">Boosting</a></li>
<li><a href="#residual-connection">Residual Connection</a></li>
<li><a href="#regularization">Regularization</a></li>
<li><a href="#multitask-embedding">Multitask Embedding</a></li>
</ul>
</li>
<li><a href="#project-3-decanlp">Project 3: DecaNLP</a>
<ul>
<li><a href="#leaderboard">Leaderboard</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="toolkit">Toolkit</h2>

<h3 class="mume-header" id="server">Server</h3>

<pre data-role="codeBlock" data-info="bash" class="language-bash"><span class="token function">ssh</span> v-hajia@v1011.westus2.cloudapp.azure.com
<span class="token function">ssh</span> v-hajia@13.66.230.50
</pre><h3 class="mume-header" id="docker">Docker</h3>

<p><a href="https://docs.docker.com/get-started/">Introduction from docker.com</a></p>
<pre data-role="codeBlock" data-info="bash" class="language-bash">docker run -it --rm  -v ~/project:/work/project biglm <span class="token function">bash</span>
docker run -it --rm  -v ~/project:/work/project fairseq <span class="token function">bash</span>
docker run -it --rm -v ~/project/MNLI:/work/MNLI --privileged tscience.azurecr.io/biglm/biglm:1.12-0.4.1-cuda9.2-py36 <span class="token function">bash</span>
</pre><h4 class="mume-header" id="run-a-docker-image">Run a docker image</h4>

<pre data-role="codeBlock" data-info="bash" class="language-bash">docker run -it --rm  -v /local_dir:/docker_dir docker-image:tag <span class="token function">bash</span>
</pre><p><code>-it</code>: interactive mode<br>
<code>--rm</code>: clean up after exit<br>
<code>-v</code>: volume (shared filesystems)</p>
<h4 class="mume-header" id="attach-to-a-running-docker-container">Attach to a running docker container</h4>

<pre data-role="codeBlock" data-info="bash" class="language-bash">docker <span class="token function">ps</span>
docker <span class="token function">exec</span> -it container_name <span class="token function">bash</span>
</pre><h4 class="mume-header" id="file-permission-issue">File Permission Issue</h4>

<p>All files created by the docker is owned by root.<br>
Solution: <a href="https://www.berthon.eu/2018/containers-volumes-and-file-permissions/">Using ACL</a><br>
The following command grant use ACL to make read/write permissions of all files in <code>project</code> inherit from project and have the same access of the current host user.</p>
<pre data-role="codeBlock" data-info="bash" class="language-bash">setfacl -dm <span class="token string">&quot;u:username:rwx&quot;</span> ~/project
</pre><h4 class="mume-header" id="build-a-docker-image">Build a docker image</h4>

<ol>
<li>Get folder with everything you need in it.</li>
<li>Write a <code>Dockerfile</code></li>
<li><code>docker build --tag=docker-image .</code></li>
</ol>
<h4 class="mume-header" id="cheatsheet">Cheatsheet</h4>

<pre data-role="codeBlock" data-info="bash" class="language-bash"><span class="token comment">## List Docker CLI commands</span>
docker
docker container --help

<span class="token comment">## Display Docker version and info</span>
docker --version
docker version
docker info

<span class="token comment">## Execute Docker image</span>
docker run hello-world

<span class="token comment">## List Docker images</span>
docker image <span class="token function">ls</span>

<span class="token comment">## List Docker containers (running, all, all in quiet mode)</span>
docker container <span class="token function">ls</span>
docker container <span class="token function">ls</span> --all
docker container <span class="token function">ls</span> -aq
</pre><h2 class="mume-header" id="project-1-semi-supervised-learning-of-mnli-by-generating-labeled-paired-sample-using-conditional-cyclegan">Project 1: Semi-supervised Learning of MNLI by Generating Labeled Paired Sample using Conditional CycleGAN</h2>

<h3 class="mume-header" id="motivation">Motivation</h3>

<p>Data vs Performance: Data <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x2191;</mo></mrow><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mrel">&#x2191;</span></span></span></span> <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x21D2;</mo></mrow><annotation encoding="application/x-tex">\Rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">&#x21D2;</span></span></span></span> Performance <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x2191;</mo></mrow><annotation encoding="application/x-tex">\uparrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mrel">&#x2191;</span></span></span></span>.<br>
However, labeled data is limited.</p>
<h3 class="mume-header" id="difficulty">Difficulty</h3>

<ol>
<li>Pairing sentences: Conditional CycleGAN</li>
<li>Diversity</li>
<li>Domain mismatch</li>
<li>How to use noisy generated data: <a href="https://niug1984.github.io/publication.html">Gang Niu</a></li>
</ol>
<h3 class="mume-header" id="ideas">Ideas</h3>

<p><strong>Dual Learning</strong>: do not find paring, generate paring!!!! Conditional generator: xxx,xxx,xxxxx + contradict --&gt; yyy,yyy,yyyyy <a href="https://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&amp;mid=2649447754&amp;idx=1&amp;sn=8ad44ffc9aad1079f8d58585d5aa58e0&amp;chksm=82c0b4ceb5b73dd8334086200cf17685c565a97b7cf09ef046d1d6ddb40ba71a3a1159a6f6c9&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;key=7009efb4b025cbdb67f09288c684aafc595e2741bfa80d5946feb44b33057940301941a2995dc9f1ee19f31832e430fa5df08f98916c741482c3c200d2ccd825a75d0779eabcbef59427a23891ee026a&amp;ascene=1&amp;uin=MjA1OTU0MjcwMg%3D%3D&amp;devicetype=Windows+10&amp;version=62060739&amp;lang=en&amp;pass_ticket=0Y%2F4Wenpbb1a5Mmkv6ITdzYVnPCjNwCSs%2B70la%2Fan8%2B1nMEqHLhsOW9rEw2xwERb">Almost Unsupervised Text to Speech and Automatic Speech Recognition<br>
</a><a href="https://speechresearch.github.io/papers/almost_unsup_tts_asr_2019.pdf">paper</a><br>
View as machine teacher.</p>
<h3 class="mume-header" id="reading-list">Reading List</h3>

<p><strong>Models</strong><br>
<a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><br>
<a href="https://blog.openai.com/language-unsupervised/">Improving Language Understanding by Generative Pre-Training</a><br>
<a href="http://arxiv.org/abs/1901.02860">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</a><br>
<a href="https://blog.openai.com/better-language-models/">Language Models are Unsupervised Multitask Learners</a><br>
<a href="https://arxiv.org/pdf/1901.07291.pdf">Cross-lingual Language Model Pretraining</a></p>
<p><a href="https://arxiv.org/abs/1804.09530">Strong Baselines for Neural Semi-supervised Learning under Domain Shift</a><br>
<a href="http://www.iro.umontreal.ca/~lisa/pointeurs/semi-supervised-entropy-nips2004.pdf">Semi-supervised Learning by Entropy Minimization</a><br>
<a href="https://arxiv.org/pdf/1905.03197.pdf">Unified Language Model Pre-training for Natural Language Understanding and Generation</a></p>
<p><strong>Data Augmentation</strong> (All of these are too heuristic)<br>
<a href="https://arxiv.org/pdf/1905.06290.pdf">A Surprisingly Robust Trick for the Winograd Schema Challenge</a>: select entities in a sentence -&gt; random mask + filtering<br>
<a href="https://arxiv.org/pdf/1904.12848">Unsupervised Data Augmentation</a>: given x -&gt; x&apos;| Training Signal Annealing<br>
<a href="https://arxiv.org/pdf/1804.09541.pdf">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>: back translation (1m-&gt;1.5m, however ours: 1m -&gt; <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>+</mo><mi mathvariant="normal">&#x221E;</mi></mrow><annotation encoding="application/x-tex">+\infty</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord">+</span><span class="mord">&#x221E;</span></span></span></span>)<br>
<a href="https://arxiv.org/pdf/1805.09501">AutoAugment: Learning Augmentation Policies from Data</a></p>
<p><strong>Semi-Supervised Learning or Weak Supervised Learning</strong><br>
<a href="https://128.84.21.199/pdf/1905.05910.pdf">PASSAGE RANKING WITH WEAK SUPERVISION</a><br>
<a href="http://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly.pdf">Data Programming: Creating Large Training Sets, Quickly</a></p>
<h3 class="mume-header" id="baselines">Baselines</h3>

<p><strong>Bootstrapping Methods</strong><br>
<a href="https://arxiv.org/abs/1804.09530">Self training</a>: Train -&gt; Collect high confident samples -&gt; loop -&gt; no more confident prediction.<br>
<a href="https://arxiv.org/abs/1804.09530">Tri-training</a>: Three models. For i-th model, if the other two agrees the label, then add that sample to the training set of i-th model. We can further share the some parameters between models.</p>
<h3 class="mume-header" id="data">Data</h3>

<p><a href="https://www.nyu.edu/projects/bowman/multinli/paper.pdf">Data</a></p>
<h2 class="mume-header" id="project-2-emsemble-model">Project 2: Emsemble Model</h2>

<p><strong>Aim:</strong> Use <em>less</em> models in the ensemble to reach equal or <em>better</em> performance.<br>
<strong>Idea:</strong> Try to encourage the diversity between the models.</p>
<h3 class="mume-header" id="boosting">Boosting</h3>

<p>Hardness: boosting is hard for strong models.</p>
<h3 class="mume-header" id="residual-connection">Residual Connection</h3>

<p>The next model can be aware of the previous model. It is similar to a simplified wide structure.</p>
<h3 class="mume-header" id="regularization">Regularization</h3>

<p>To encourage model diversity, we can use add regularization.</p>
<p><strong>Penalize parameters:</strong> For example, we can use orthogonal regularization to penalize the similarity between the weight matrices of two models. Take linear regression <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><msup><mi>x</mi><mi mathvariant="normal">&#x22A4;</mi></msup><mi>b</mi></mrow><annotation encoding="application/x-tex">y = x^\top b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.849108em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">&#x22A4;</span></span></span></span></span></span></span></span><span class="mord mathdefault">b</span></span></span></span> as a simple example. Assume there is a lot of redundancy in <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>, we can have <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">b_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">b_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>b</mi><mn>1</mn><mi mathvariant="normal">&#x22A4;</mi></msubsup><msub><mi>b</mi><mn>2</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">b_1^\top b_2=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.097216em;vertical-align:-0.24810799999999997em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">&#x22A4;</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span> and both of them are near optimal. So generally, we can penalize similarity between the weight matrices by the F-norm <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">&#x2223;</mi><mi mathvariant="normal">&#x2223;</mi><msubsup><mi>W</mi><mn>1</mn><mi mathvariant="normal">&#x22A4;</mi></msubsup><msub><mi>W</mi><mn>2</mn></msub><mi mathvariant="normal">&#x2223;</mi><mi mathvariant="normal">&#x2223;</mi></mrow><annotation encoding="application/x-tex">||W_1^\top W_2||</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.099108em;vertical-align:-0.25em;"></span><span class="mord">&#x2223;</span><span class="mord">&#x2223;</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.4518920000000004em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">&#x22A4;</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.24810799999999997em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">&#x2223;</span><span class="mord">&#x2223;</span></span></span></span>. And then we jointly train these two model. We can just apply these penalties to the bottom layers to encourage diversity. (<em>I am not sure if this intuition is right</em>)</p>
<p><strong>Encourage embedding diversity:</strong> We next consider the embedding space. For a given input <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>, the embedding of two models are <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mn>1</mn></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">E_1(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>E</mi><mn>2</mn></msub><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">E_2(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>. We then try to encourage the diversity embedding by adding regularization. For example, we can use Euclidean optimal transport regularization, i.e., <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x2212;</mo><msub><mi mathvariant="double-struck">E</mi><mi>x</mi></msub><mo>[</mo><mi mathvariant="normal">&#x2223;</mi><mi mathvariant="normal">&#x2223;</mi><msub><mi>E</mi><mn>1</mn></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>&#x2212;</mo><msub><mi>E</mi><mn>2</mn></msub><mo>(</mo><mi>x</mi><mo>)</mo><mi mathvariant="normal">&#x2223;</mi><msup><mi mathvariant="normal">&#x2223;</mi><mn>2</mn></msup><mo>]</mo></mrow><annotation encoding="application/x-tex">-\mathbb{E}_x[||E_1(x)-E_2(x)||^2]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">&#x2212;</span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord">&#x2223;</span><span class="mord">&#x2223;</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">&#x2212;</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mord">&#x2223;</span><span class="mord"><span class="mord">&#x2223;</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span>. We can just apply these penalties to the bottom layers to encourage diversity.</p>
<h3 class="mume-header" id="multitask-embedding">Multitask Embedding</h3>

<p>We can use a discriminator to differentiate which model is the embedding coming from. And then, we can use multitask learning to encourage the embedding to be different. This needs to be further twisted. Because it may fall into an undesired situation. For example, the dimension of embedding is 10. The last dimension contains the exact model information and has nothing to do with the other part of the model. The other 9 features are exactly the same for different models. The discriminator will fully depend on the last feature. Such a multitask embedding does not help the model diversity.</p>
<h2 class="mume-header" id="project-3-decanlp">Project 3: DecaNLP</h2>

<p><a href="https://github.com/salesforce/decaNLP">DecaNLP</a> is a multitask challenge that spans ten tasks. Each task is cast as question answering, which makes the training the same as single task training.</p>
<img src="decanlp_example.PNG?0.0434476598833311" height="300px" title="Deca NLP">
<p>Each sample consists of three parts: Question, Context, and Answer.</p>
<p><strong>Idea</strong> The basic idea is to consider the heterogeneous encoding/decoding process of different tasks. Following the framework in <a href="https://arxiv.org/abs/1806.08730">MQAN</a>, we have 2 encoders for question and context, and one decoding process with an RNN.</p>
<p><strong>Encoder</strong> There is little to say about the context encoder. However, we can see a significant difference in the question descriptions. For example, the summarization tasks always have the question: &quot;What is the summary&quot;. For the sentiment analysis and pronoun resolution, it is always something like &quot;XXXX A or B&quot;. However, the encoding process is using the same encoder. We can try to refine this part by an encoder with different bottoms. Each bottom roughly corresponds to a class of questions. An encoder with 3 bottoms will look like the following picture:<br>
<img src="multibottomencoder.png?0.39360691705697115" height="200px" title="multimodule encoder"><br>
Here <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>g</mi><mn>1</mn><mo separator="true">,</mo><mi>g</mi><mn>2</mn><mo separator="true">,</mo><mi>g</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">g1,g2,g3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">3</span></span></span></span> are task-specific gated weight. Like if the task always have the question description as &quot;XXXX A or B&quot;, we may have <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>g</mi><mn>1</mn><mo>=</mo><mn>0.9</mn><mo separator="true">,</mo><mi>g</mi><mn>2</mn><mo>=</mo><mn>0.05</mn><mo separator="true">,</mo><mi>g</mi><mn>3</mn><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">g1=0.9,g2=0.05,g3=0.05</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span></span></span></span>. If the task always has a fix description such as the summary task, we may have <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>g</mi><mn>1</mn><mo>=</mo><mn>0.05</mn><mo separator="true">,</mo><mi>g</mi><mn>2</mn><mo>=</mo><mn>0.9</mn><mo separator="true">,</mo><mi>g</mi><mn>3</mn><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">g1=0.05,g2=0.9,g3=0.05</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span></span></span></span>. For any other tasks with general task description we may have <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>g</mi><mn>1</mn><mo>=</mo><mn>0.05</mn><mo separator="true">,</mo><mi>g</mi><mn>2</mn><mo>=</mo><mn>0.05</mn><mo separator="true">,</mo><mi>g</mi><mn>3</mn><mo>=</mo><mn>0.9</mn></mrow><annotation encoding="application/x-tex">g1=0.05,g2=0.05,g3=0.9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span></span></span></span>.</p>
<p><strong>Decoder</strong> The decoding processes, i.e., the answer generating processes are also quite different for different tasks. Roughly speaking, there are mainly three different generating processes: 1. Some pick important parts from Contexts, such as SQuAD and Summarization. 2. Some need to generate answer from vocabulary just like translation. 3. The others basically pick the important part from the Question. We thus can use 3 different parameter sets for the decoder. Just like the encoder part, each task has a soft membership over these 3 classes. We can mix three different decoders by the soft membership.</p>
<h3 class="mume-header" id="leaderboard">Leaderboard</h3>

<table>
<thead>
<tr>
<th>Model</th>
<th>decaNLP</th>
<th><a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a></th>
<th><a href="https://wit3.fbk.eu/mt.php?release=2016-01">IWSLT</a></th>
<th><a href="https://cs.nyu.edu/~kcho/DMQA/">CNN/DM</a></th>
<th><a href="https://www.nyu.edu/projects/bowman/multinli/">MNLI</a></th>
<th><a href="https://nlp.stanford.edu/sentiment/treebank.html">SST</a></th>
<th><a href="https://dada.cs.washington.edu/qasrl/">QA&#x2011;SRL</a></th>
<th><a href="http://nlp.cs.washington.edu/zeroshot/">QA&#x2011;ZRE</a></th>
<th><a href="https://github.com/nmrksic/neural-belief-tracker/tree/master/data/woz">WOZ</a></th>
<th><a href="https://github.com/salesforce/WikiSQL">WikiSQL</a></th>
<th><a href="https://s3.amazonaws.com/research.metamind.io/decaNLP/data/schema.txt">MWSC</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://arxiv.org/abs/1806.08730">MQAN</a>(Sampling+<a href="http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors">CoVe</a>)</td>
<td>609.0</td>
<td>77.0</td>
<td>21.4</td>
<td>24.4</td>
<td>74.0</td>
<td>86.5</td>
<td>80.9</td>
<td>40.9</td>
<td>84.8</td>
<td>70.2</td>
<td>48.8</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1806.08730">MQAN</a>(QA&#x2011;first+<a href="http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors">CoVe</a>)</td>
<td>599.9</td>
<td>75.5</td>
<td>18.9</td>
<td>24.4</td>
<td>73.6</td>
<td>86.4</td>
<td>80.8</td>
<td>37.4</td>
<td>85.8</td>
<td>68.5</td>
<td>48.8</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1806.08730">MQAN</a>(QA&#x2011;first)</td>
<td>590.5</td>
<td>74.4</td>
<td>18.6</td>
<td>24.3</td>
<td>71.5</td>
<td>87.4</td>
<td>78.4</td>
<td>37.6</td>
<td>84.8</td>
<td>64.8</td>
<td>48.7</td>
</tr>
<tr>
<td><a href="https://arxiv.org/abs/1806.08730">S2S</a></td>
<td>513.6</td>
<td>47.5</td>
<td>14.2</td>
<td>25.7</td>
<td>60.9</td>
<td>85.9</td>
<td>68.7</td>
<td>28.5</td>
<td>84.0</td>
<td>45.8</td>
<td>52.4</td>
</tr>
</tbody>
</table>

      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>