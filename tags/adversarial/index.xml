<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Adversarial on Haoming Jiang</title>
    <link>http://localhost:1313/tags/adversarial/</link>
    <description>Recent content in Adversarial on Haoming Jiang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 23 Jan 2021 22:49:12 -0500</lastBuildDate><atom:link href="http://localhost:1313/tags/adversarial/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Our Adversarial Training Paper has been Accepted by AISTATS 2021</title>
      <link>http://localhost:1313/news/aistats2021/</link>
      <pubDate>Sat, 23 Jan 2021 22:49:12 -0500</pubDate>
      
      <guid>http://localhost:1313/news/aistats2021/</guid>
      <description>Our Adversarial Training Paper has been Accepted by AISTATS 2021. We propose a learning-to-learn method to improve adversarial training on a variety of tasks.
Reference Learning to Defense by Learning to Attack 2021 Zhehui Chen*, Haoming Jiang*, Yuyang Shi, Bo Dai, and Tuo Zhao (* Equal Contribution) [arXiv] The 24th International Conference on Artificial Intelligence and Statistics (AISTATS), 2021 </description>
      <content>&lt;p&gt;Our Adversarial Training Paper has been Accepted by AISTATS 2021.
We propose a learning-to-learn method to improve adversarial training on a variety of tasks.&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
&lt;span style=&#34;color:white;font-weight:bold;&#34;&gt;Learning to Defense by Learning to Attack&lt;/span&gt; &lt;span style=&#34;float:right;font-weight:bold;&#34;&gt;2021&lt;/span&gt;&lt;br/&gt;
&lt;span style=&#34;color:LightGrey&#34;&gt;Zhehui Chen*, Haoming Jiang*, Yuyang Shi, Bo Dai, and Tuo Zhao (* Equal Contribution)&lt;/span&gt;
 &lt;a href=&#34;https://arxiv.org/pdf/1811.01213.pdf&#34;&gt;[arXiv]&lt;/a&gt;




 &lt;br/&gt; &lt;strong&gt;&lt;em style=&#34;color:LightGrey&#34;&gt;The 24th International Conference on Artificial Intelligence and Statistics (AISTATS)&lt;/em&gt;&lt;/strong&gt;, 2021


&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>Our BERT Calibration Paper has been Accepted by EMNLP 2020</title>
      <link>http://localhost:1313/news/emnlp2020/</link>
      <pubDate>Wed, 23 Dec 2020 22:49:01 -0500</pubDate>
      
      <guid>http://localhost:1313/news/emnlp2020/</guid>
      <description>We propose to improve BERT model calibration via on-manifold smoothing and off-manifold smoothing.
Reference Calibrated Fine-Tuning for Pre-trained Language Models via Manifold Smoothing 2020 Lingkai Kong, Haoming Jiang, Yuchen Zhuang, Jie Lyu, Tuo Zhao and Chao Zhang [arXiv] Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020 </description>
      <content>&lt;p&gt;We propose to improve BERT model calibration via on-manifold smoothing and off-manifold smoothing.&lt;/p&gt;
&lt;h3 id=&#34;reference&#34;&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;
&lt;span style=&#34;color:white;font-weight:bold;&#34;&gt;Calibrated Fine-Tuning for Pre-trained Language Models via Manifold Smoothing&lt;/span&gt; &lt;span style=&#34;float:right;font-weight:bold;&#34;&gt;2020&lt;/span&gt;&lt;br/&gt;
&lt;span style=&#34;color:LightGrey&#34;&gt;Lingkai Kong, Haoming Jiang, Yuchen Zhuang, Jie Lyu, Tuo Zhao and Chao Zhang&lt;/span&gt;
 &lt;a href=&#34;https://arxiv.org/pdf/2010.11506.pdf&#34;&gt;[arXiv]&lt;/a&gt;




 &lt;br/&gt; &lt;strong&gt;&lt;em style=&#34;color:LightGrey&#34;&gt;Conference on Empirical Methods in Natural Language Processing (EMNLP)&lt;/em&gt;&lt;/strong&gt;, 2020


&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
  </channel>
</rss>
